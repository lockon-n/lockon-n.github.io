---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am currently a second-year Master's student at [Shanghai Jiao Tong University](https://en.sjtu.edu.cn/), under the supervision of [Prof. Hai Zhao](https://bcmi.sjtu.edu.cn/home/zhaohai/), majoring in computer science. Before that, I received my B.S. degree in the IEEE honor class at SJTU in 2022, majoring in computer science. I also collaborated with [Dr. Zhuosheng Zhang](https://bcmi.sjtu.edu.cn/~zhangzs/) during my undergraduate years.

I used to work as a research intern at Microsoft Research Asia (MSRA) in the [NLC group](https://www.microsoft.com/en-us/research/group/natural-language-computing/), guided by [Dr. Lei Cui](https://www.microsoft.com/en-us/research/people/lecu/). I worked on several interesting research topics related to Document AI, including webpage understanding and document Image foundation models.

Currently, I work closely with [Prof. Pengfei Liu](http://pfliu.com/) at [GAIR](https://plms.ai/) on various aspects of Large Language Models (LLMs), primarily focusing on the evaluation and alignment of LLMs.

# Publications

(* indicates equal contribution)

<div class='paper-box-text' markdown="1">
<font color="CornFlowerBlue">Generative Judge for Evaluating Alignment
</font>
**Junlong Li**, Shichao Sun, Weizhe Yuan, Run-Ze Fan, Hai Zhao, Pengfei Liu \\
**Preprint, 2023** |  [PDF](https://arxiv.org/abs/2310.05470) | [Code](https://github.com/GAIR-NLP/auto-j) | [Page](https://gair-nlp.github.io/auto-j/)
</div>

<div class='paper-box-text' markdown="1">
<font color="CornFlowerBlue">Generative AI for Math: Abel</font>
Ethan Chern\*, Haoyang Zou\*, Xuefeng Li\*, Jiewen Hu\*, Kehua Feng, **Junlong Li**, Pengfei Liu \\
**Preprint, 2023** | [Code](https://github.com/GAIR-NLP/abel) | [Page](https://gair-nlp.github.io/abel/)
</div>

<div class='paper-box-text' markdown="1">
<font color="CornFlowerBlue">Self-prompted Chain-of-Thought on Large Language Models for
Open-domain Multi-hop Reasoning</font>
Jinyuan Wang, **Junlong Li**, Hai Zhao \\
**(EMNLP 2023, Findings)** | [Code](https://github.com/noewangjy/SP-CoT)
</div>

<div class='paper-box-text' markdown="1">
<font color="CornFlowerBlue">Self-Prompting Large Language Models for Zero-Shot Open-Domain QA</font>
**Junlong Li**, Zhuosheng Zhang, Hai Zhao \\
**Preprint, 2022** |  [PDF](https://arxiv.org/abs/2212.08635) 
</div>

<div class='paper-box-text' markdown="1">
<font color="CornFlowerBlue">Dialogue-adaptive language model pre-training from quality estimation
</font>
**Junlong Li**, Zhuosheng Zhang, Hai Zhao \\
Neurocomputing, 2022 |  [PDF](https://arxiv.org/abs/2009.04984) | [Code](https://github.com/lockon-n/DAPO)
</div>

<div class='paper-box-text' markdown="1">
<font color="CornFlowerBlue">DiT: Self-supervised pre-training for document image transformer
</font>
**Junlong Li**, Yiheng Xu, Tengchao Lv, Lei Cui, Cha Zhang, Furu Wei \\
ACM Multimedia 2022 |  [PDF](https://arxiv.org/abs/2203.02378) | [Code](https://github.com/microsoft/unilm/tree/master/dit)
</div>

<div class='paper-box-text' markdown="1">
<font color="CornFlowerBlue">Markuplm: Pre-training of text and markup language for visually-rich document understanding
</font>
**Junlong Li**\*, Yiheng Xu\*, Lei Cui, Furu Wei \\
ACL 2022 |  [PDF](https://arxiv.org/abs/2110.08518) | [Code](https://github.com/microsoft/unilm/tree/master/markuplm)
</div>

<div class='paper-box-text' markdown="1">
<font color="CornFlowerBlue">Multi-turn dialogue reading comprehension with pivot turns and knowledge
</font>
Zhuosheng Zhang, **Junlong Li**, Hai Zhao \\
TASLP, 2021 |  [PDF](https://arxiv.org/abs/2102.05474) | [Code](https://github.com/lockon-n/KKT)
</div>

# Educations

- *2022.09 - 2025.03 (expected)*, M.S.@SJTU, Computer Science & Engineering
- *2018.09 - 2022.06*, B.S.@SJTU, IEEE honor class, Computer Science.

# Talks

- *2023.10*, Invited talk at CIKM 2023 Workshop on Document Intelligence and Understanding.

# Awards

- MSRA Stars of Tomorrow (Award of Excellent Intern), 2022

- National Scholarship (top 2%), 2022

- SJTU Zhiyuan Honors Scholarship (top 5%), 2019-2021